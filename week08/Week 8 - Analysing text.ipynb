{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa76c76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2e71e8",
   "metadata": {},
   "source": [
    "# Download and tokenise a book\n",
    "In this exercise, we will download the text from a book, we will use Les Miserables by Victor Hugo for other sections, but you can try with any other book available from Project Gutenberg or elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "800b7c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_url0 = 'http://www.gutenberg.org/files/135/135-0.txt'\n",
    "book_raw = urlopen(target_url0).read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da390c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(book_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad0df3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3324222"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11fb0c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Project Gutenberg eBook of Les Misérables, by Victor Hugo\\r\\n\\r\\nThis eBook is for the use of anyone anywhere in the United States and\\r\\nmost other parts of the world at no cost and with almost no restrictions\\r\\nwhatsoever. You may copy it, give it aw'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_raw[1:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d25d981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg eBook of Les Misérables, by Victor Hugo\r\n",
      "\r\n",
      "This eBook is for the use of anyone anywhere in the United States and\r\n",
      "most other parts of the world at no cost and with almost no restrictions\r\n",
      "whatsoever. You may copy it, give it aw\n"
     ]
    }
   ],
   "source": [
    "print(book_raw[1:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ad495fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Project', 'Gutenberg', 'eBook', 'of', 'Les', 'Misérables', ',', 'by', 'Victor', 'Hugo', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever']\n"
     ]
    }
   ],
   "source": [
    "word_tokens = word_tokenize(book_raw)\n",
    "print(word_tokens[1:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cb53f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this']\n"
     ]
    }
   ],
   "source": [
    "stop_words = (stopwords.words('english'))\n",
    "print(stop_words[1:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5e09d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Project', 'Gutenberg', 'eBook', 'Les', 'Misérables', ',', 'Victor', 'Hugo', 'This', 'eBook', 'use', 'anyone', 'anywhere', 'United', 'States', 'parts', 'world', 'cost', 'almost', 'restrictions', 'whatsoever', '.', 'You', 'may', 'copy', ',', 'give', 'away', 're-use', 'terms', 'Project', 'Gutenberg', 'License', 'included', 'eBook', 'online', 'www.gutenberg.org', '.', 'If']\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words from tokenised works\n",
    "word_tokens_filtered = [word for word in word_tokens if word not in stop_words]\n",
    "\n",
    "# Print the answer\n",
    "print(word_tokens_filtered[1:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7825b31",
   "metadata": {},
   "source": [
    "# Lengthy books\n",
    "\n",
    "Can you find other books that are longer than Les Miserables? For example, compare with The count of Monte-cristo:\n",
    "\n",
    "https://www.gutenberg.org/files/1184/1184-0.txt  \n",
    "Or what about that very very very long book by Leo Tolstoy?\n",
    "\n",
    "https://www.gutenberg.org/files/2600/2600-0.txt  \n",
    "\n",
    "You can try books in other languages as well, like Don Quijote in Spanish:\n",
    "http://www.gutenberg.org/cache/epub/2000/pg2000.txt  \n",
    "\n",
    "Find out which book has more words. (Be aware that Project Gutenberg adds a preamble and then some notices after the book, this may have a stronger impact in shorter books). \n",
    "\n",
    "**NOTE**: if you get an error dowloading a book, try a different version, for instance for Don Quijote you can try the English version:\n",
    "\n",
    "https://www.gutenberg.org/cache/epub/996/pg996.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b2a7ca",
   "metadata": {},
   "source": [
    "Count how **many sentences** each book has. We could expect that a longer book will have more sentences, but one interesting comparison is how long is the average sentence in each book. Find out the **average length of a sentence** in each book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7803f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tokens = sent_tokenize(book_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5be2ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He very soon returned to D—— He was\r\n",
      "interrogated as to this speedy return, and he replied: _“I embarrassed\r\n",
      "them.\n"
     ]
    }
   ],
   "source": [
    "print(sentences_tokens[1001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b86b85dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29649"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many sentences a book has\n",
    "len(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6df5f45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length: 112.11919457654558\n"
     ]
    }
   ],
   "source": [
    "# Find the average length\n",
    "print(\"Average length: \" + str(len(book_raw)/ len(sentence_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8c44ca",
   "metadata": {},
   "source": [
    "Finally, do authors repeat many times the same words or do they have an large vocabulary and use many different words? We can explore that with another function from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac36a033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 48757, 'the': 36547, '.': 26190, 'of': 19596, 'and': 14028, 'a': 13412, 'to': 13325, 'in': 10239, 'was': 8536, 'that': 7252, ...})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting a frequency\n",
    "freq_dist = FreqDist(word_tokens)\n",
    "freq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "329814e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30354\n"
     ]
    }
   ],
   "source": [
    "# Put it frequency in the dict\n",
    "freq_dist_dict = dict((word, freq) for word, freq in freq_dist.items())\n",
    "\n",
    "# Print the resolution\n",
    "print(len(freq_dist_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
